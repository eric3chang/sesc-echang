[[Title: An Implementation of the standard directory-based cache-coherence protocol on the SESC simulator]]
[[Title: An analysis of directory-based cache-coherence protocol on symmetric multiprocessors using the SESC simulator]]



[[Section 1 Comparing different directory-based cache coherence protocols.]]

[[Section 01-2]]

"In a coherent multiprocessor, the caches provide both migration and replication of shared data items" (Hennessey 207). It is important for the architect of the processor to design these features into the processor as to allow the programmer to take advantage of the speedup available in having multiple data. Having multiple data allows for multiple reads at the same time.

Read Request   Read Request
   |              |           Time
Cache01        Cache02

Read Request
   |              Time
Cache 01          |
                  |
Read Request      |
   |              Time
Cache 01


[[Section 02 Different Types of Cache Coherence Protocols]]

There are two main types of cache coherence protocols - Directory based and snooping. A third one is available on Wikipedia. In my report, we will focuson directory-based cache coherence protocols and what they bring to the table. 

There are several cache-coherence protocols. 

When it comes to cache-coherence, there are several types. There is the directory-based cache-coherence protocl, first invented in 

In this report, I will talk about different directory-based protocols and how they compare against each other. 

Snoopy-based protocols have an advantage when it comes to manufacturing because they can use the existing bus to memory as the broadcast medium for communicating information about cache coherence (Hennessey 208). However, from the results in the following table, we can see that a snoopy-based protocol is not as scalable as a directory-based protocol. So in my report, we will check
out various directory-based protocols.

[Figure comparing snoopy-based protocol vs directory-based protocol]
# of processors
% speedup
# of collisions

[[Section01.3 Why Directory-based cache coherence protocols is advantageous for the future]]

"As processor speeds and the number of cores per processor increase, more designers are likely to opt for [directory-based cache coherence] protocols to avoid the broadcase limit of a snoopy protocol (217 Hennessey).

[[Section 03.1 Changing Cache Size]]

increasing cache size increases coherence misses because more invalidates occur because fewer blocks are bumped due to capacity misses. Of course, capacity misses decrease because the cache has more spaces to put blocks (Hennessey 229).

Increasing blocksize means capacity miss decreases and compulsory miss decreases for certain applications. When this happens, it most likely means that there is a lot of spatial locality in the code, such as when running kernel code. Because increasing blocksize grabs more of the code in the same area together, which directly reduces compulsory misses. The capacity miss is reduced because we're storing more of the necessary code in the cache (Hennessey 228).

[[Section 04]]
Section 04 Table. What MOESI means to each memory unit

[[Section 04.1 Directory-Based Cache-Coherence Protocol]]
A directory-based cache-coherence protocol can be designed several ways. One of the easiest ways to keep track of the directories is to keep a bit vector in each distributed directory about which CPU has which cache block. Another way would be to keep track of the nodeID. The advantage of using a nodeID is that it can potentially take up less space in the directory. However, there is a disadvantage to keeping track of the nodeID. Usually, in a nodeID-based directory-based cache-coherence system, we do not keep track of all the nodeID's because that would defeat the primary purpose of using the nodeID to keep track of which CPU's contain a specific cache block, which is to save space. So usually, when we have a system that keeps track of the cache block using nodeID, we are unable to keep track of all the CPU's that might potentially request for a cache block. In which case, we would have to tell a CPU that have a cache block to mark their copy as invalid so we can free up a space in the directory.

In this way, we can see that using bit vector to keep track of the CPU that has a specific cache block is an efficient way to implement directory-based cache-coherence protocol, but it has a certain limit on how many CPU's can be used together with the system.

[[Section 05.1 Network]]
The underlying network in use for this simulator is a simple blackbox model. It does not model a real network that has routing issues. Instead it models messages going in and out of the network using a random delay with a lower-bound of [] and an upper-bound of []. When more messages arrhive, the delay coming from the random delay generator will be shifted higher as to model the higher traffic conditions.

The reason the network is not simulated in detail is because that is not the focus of this report. The focus of this report is on the various directory-based cache-coherence protocols that are able to be modeled using the SESC simulator. Although the SESC simulator has the capability to model a network, a simple network, such as the one used here, can illustrate our point.

A more complicated network would be one that simulates router-router
connection and uses routing protocols


[[Section 06.1 SESC Simulator]]
CPU_0
   |
ProcessorInterface_0
(SESCInterface)
   |
L1_0
(MOESICache)
   |
L2_0
(MOESICache)
   |
Directory_0
(Directory)
   |
Network
(RandomLoadNetwork)

The SESC simulator supports both a regular mode, where everything is simulated, and a rabbit mode, which only simulates the timing. Rabbit mode is about 1000 times faster than the regular mode, but since the Memory System is implemented in the regular mode, most of the programs are run in that mode. {Since the memory portion of the simulator is stored in the non-rabbit mode, we run all our applications out of rabbit mode.} (from SESC documents).

The user-defined values could be contained in the configuration file or passed on the command-line like the other parameters. The configuration file is read through OSSim.cpp file under the libcore folder. It is read into a SescConf variable. I will design the SimpleDirectoryController in a way so that most of the common parameters will be changeable through the header file. The most obvious parameter that comes to mind is the directory size parameter, but more options will be added as necessary to increase the flexibility of the simulator. Some of the parameters that will need to be tracked are how many accesses to the directory are being made, how many reads and writes to the
directory, and so on.

[[Section 06.xx MOESI Cache]]
The MOESI protocol was used in both L1 and L2 cache. This protocol was chosen because it contains the most states. The advantages to that is that it reduces the traffic going across the network. The "Owned" state allows dirty lines to be shared quickly (Wikipedia MOESI). The disadvantage of this protocol is that it uses the most amount of space to store this information, since it needs to store more states, compared to MESI, MOSI, or MSI protocols.

The cache size can be determined by associativity * number of sets * width. For example, in my system, this could be 4 * 4 * 64, in the case of the L1 cache. This gives it 16 blocks of 64-bit data to have a 1kB L1 cache. In the case of the L2 cache, I used an assotiativity of 4 with 8 sets to get 32 blocks. this equates to a 2kB cache.

[[Section 06.xx Directory]]
In a directory-based cache-coherence protocol, lookups will always go to the directory. However, data replies can either go through the directory, first, or it can go straight to the requester. In my implementation of the directory, the data reply go to the directory first, and the directory decides who the original requester is and forwards the data to the original requester.

The directory needs to keep track of which CPU has which cache line. This is necessary because the directory acts as the communication between each CPU. In a snoopy system, we have no way of keeping track of which CPU has which cache block. This is the advantage in the directory-based cache-coherence procotol that allows lesser traffic to be sent.

Also, the directory is required to store more than just which CPU currently contains a cache line from the current directory. It is also necessary for the directory to store what state the directory is in. If we did not store the state of the directory, we would have to query all the processors to find out what state they are all storing, which would be incredibly inefficient. 

The directory also has to keep track of the 5 states of MOESI cache. However, unlike the cache, it is possible that the directory may need to store more than one state at a time. This occurs only when one of the cache line is in the owner state and other cache lines are in the shared state.

The following are the possible data that one can hold in each cache line in the Directory.

M : {P}
S : {any number of P}
E : {P}
I : {NULL}
O : {P-owner} {Shared P}

in the bit-vector case, we can have an extra entry to store the address of the owner. Or we can indicate owner using an extra bit in each cache line. We can also keep owner at the top of the list, to indicate an owner.

Keeping track of the owner could be done by either adding a bit to each directory entry, or making sure the owner is on the very top, or simply not keeping track of it at all and using S for it. In the last method, the directory that contains the owner would be responsible for updating other directories that are requesting for the value. However, this would be somewhat difficult, because any request to the directory would return the old value from the memory. In a snoopy protocol, this is not a problem, since the owner can just intercept a read request. However, in a directory-based cache-coherence protocol, the owner directory cannot see all the requests. Therefore, the directory should keep track of the owner somehow.

The (remoteNode == nodeID) check in these places [and you'll see a similar check in a few places] is done to prevent an access where the sending node is also the home node or destination node, from emitting a network message addressed to itself.

For example, given if processor 1 requests a block A, where processor 1 is block A's home node, the pattern I described to you earlier would be to send a network message from processor 1 [requester] to processor 1 [home node].  Since this is pretty pointless, and just results in needless network traffic, I perform a check to see if the destination for a message is the same as the source of the message, previous to sending the network msg.  If this is the case, it just forwards it straight on to the function that would handle it on the local directory node [with a delay added for lookup or whatever], rather than emitting something on the network.

[[Section 06.xx.2 Scenarios for the Directory]]
Read miss message from CPU when when block is not held in any cache line: OnLocalRead, OnDirectoryBlockRequest, OnRemoteRead, OnDirectoryBlockResponse

invalidate message comes from the network:


[[Section 07.1 Simple C Program]]
Here I will demonstrate a simple c program. The purpose of this program is to demonstrate more clearly what is going on at the detailed directory-level. This program has a global variable that a function accesses. The main() function will split off threads of this function. We can see what goes on in the directory from this simple program.

[[Section 07.2 benchmarks]]
The second step to verifying whether or not the simulator is correct is to run the benchmark on a normal machine, using C code, find out what the output is, then run the program on SESC. The output produced from SESC should be
identical to that produced by running the benchmark on a real processor. If not, then it means that the program that simulates the directory protocol is not running correctly.

[[ Section 08.1 benchmarks for genome]]

a typical parameter could be -t2 -g256 -s16 -n16384

[[ Section 09.1 problems]]
In implementing the directory-based cache-coherence protocol, there were some problems. One was simply that debugging such a large system is inherently hard. It is useful to print out each message that pass around the system. However, often the bug surfaces after tens of thousands of messages are sent. At this point, it is useful to oknow the transistion states of what each message should cause. For example, a read miss request from the CPU when the block is not held in any cache line typically causes these for methods to be called: OnLocalRead, OnDirectoryBlockRequest, OnRemoteRead, and finally, OnDirectoryBlockResponse. If any of those four methods are not called for the same MsgID when satisfying a miss request, something might be wrong.

[[Section 99]]
Include state-transition diagrams for MOESI and for MSI

The MESI protocol adds an "Exclusive" state to reduce the traffic caused by writes of blocks that only exist in one cache. The MOSI protocol adds an "Owned" state to reduce the traffic caused by write-backs of blocks that are read by other caches. The MOESI protocol does both of these things. [copied from Wikipedia]

CPU1 - CPU2
 |      |
cache   cache
 |         |
memA       memA

If cpu1 and cpu2 are using the same piece of memory, then when cpu1 modifies memA, cpu2 needs to know that its copy of memA is no longer valid. This is what a cache coherence protocol does. There are several cache coherence
protocols. [list cache coherence protocols]

There are also several cache coherence mechanisms that enables these cache coherence protocols to be done.

From wikipedia. We also need to talk about consistency models, which are contracts between thethe system and the programmer. Essentially, these models state that if the programmer follows a specific set of rules, the memory of the system would be consistent with the intentions of the programmers. However, if the programmer does not follow these rules, then the memory would be inconsistent and undeterministic. There are several levels of consistency. Certain processors allow for multiple levels of consistency. For example, Intel's Itanium processor allows for [blah] by using [blah], while using [blah], we can get a higher level of consistency, at the possible expense of a speed loss.

While taking care of cache coherency, we also need to keep in mind that Amdahl's law prevents us from improving our speedup to a certain degree if our program contains sequential code. Since sequential code cannot be sped up, we can never achieve a speedup faster than the time it takes to run that sequential code.


[Skewed Cache]
Skewed cache is better than regular set-associative cache
(A case for two-way skewed-associative caches)
(Andre Seznec page 4) 
